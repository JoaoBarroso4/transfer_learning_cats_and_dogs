{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM26s2j1/foev5J9Egy+A7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoBarroso4/transfer_learning_cats_and_dogs/blob/main/transfer_learning_cats_and_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 1: Importar as bibliotecas.**"
      ],
      "metadata": {
        "id": "vl9x5cJUUw5L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_p4O2pVS-JG",
        "outputId": "89b865c7-5ddc-43fb-a15d-d873046d9136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "# Montar Google Drive para salvar o modelo\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 2: Baixar e extraiar o conjunto de dados**"
      ],
      "metadata": {
        "id": "MlSh6UYVU5j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To get a new link, if the one below is not working, visit: https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n",
        "    -O kagglecatsanddogs.zip\n",
        "\n",
        "# Criar diretório para extrair o conjunto de dados\n",
        "dataset_dir = '/content/cats_and_dogs'\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "# Extrair o conjunto de dados\n",
        "with zipfile.ZipFile('kagglecatsanddogs.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(dataset_dir)\n",
        "\n",
        "# Verificar o conteúdo do diretório\n",
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MabsJtPYTGdg",
        "outputId": "5585f0b0-4aa7-4420-bb72-16787cb37f8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-10 18:22:49--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.59.26.17, 2600:1408:ec00:f86::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.59.26.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824887076 (787M) [application/octet-stream]\n",
            "Saving to: ‘kagglecatsanddogs.zip’\n",
            "\n",
            "kagglecatsanddogs.z 100%[===================>] 786.67M  93.6MB/s    in 7.5s    \n",
            "\n",
            "2024-06-10 18:22:57 (104 MB/s) - ‘kagglecatsanddogs.zip’ saved [824887076/824887076]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['readme[1].txt', 'CDLA-Permissive-2.0.pdf', 'PetImages']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 3: Pré-processamento dos dados**"
      ],
      "metadata": {
        "id": "sqwoOygVVA8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para verificar se a imagem está corrompida\n",
        "def is_image_corrupted(file_path):\n",
        "    try:\n",
        "        img = Image.open(file_path)\n",
        "        img.verify()  # Verificar se a imagem pode ser aberta\n",
        "        return False\n",
        "    except (IOError, SyntaxError) as e:\n",
        "        print(f\"Corrupted image: {file_path}\")\n",
        "        return True\n",
        "\n",
        "# Remover imagens corrompidas\n",
        "def remove_corrupted_images(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if is_image_corrupted(file_path):\n",
        "                os.remove(file_path)\n",
        "\n",
        "# Diretório base onde estão as pastas \"Cat\" e \"Dog\"\n",
        "base_dir = os.path.join(dataset_dir, 'PetImages')\n",
        "remove_corrupted_images(base_dir)  # Remover imagens corrompidas\n",
        "\n",
        "# Configurar data augmentation e preparação dos dados\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Dividir dados em treinamento e validação\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkzZWWiyVJ09",
        "outputId": "79780239-9b4d-4cca-d0ac-a42fef4465da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrupted image: /content/cats_and_dogs/PetImages/Cat/666.jpg\n",
            "Corrupted image: /content/cats_and_dogs/PetImages/Cat/Thumbs.db\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrupted image: /content/cats_and_dogs/PetImages/Dog/11702.jpg\n",
            "Corrupted image: /content/cats_and_dogs/PetImages/Dog/Thumbs.db\n",
            "Found 20000 images belonging to 2 classes.\n",
            "Found 4998 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 4: Construir o modelo**"
      ],
      "metadata": {
        "id": "i7oSg4qAZKqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir o modelo\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aaPEH2eHZQKY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 5: treinar o modelo**"
      ],
      "metadata": {
        "id": "k5_if34LZZJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Salvar o modelo\n",
        "model.save('/content/drive/My Drive/cats_and_dogs_classifier.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGCTlufhZcUO",
        "outputId": "304e98bf-a89c-4705-a2eb-de108e7b19f1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 - 82s - loss: 0.7634 - accuracy: 0.5420 - val_loss: 0.6759 - val_accuracy: 0.6200 - 82s/epoch - 819ms/step\n",
            "Epoch 2/15\n",
            "100/100 - 86s - loss: 0.6632 - accuracy: 0.6140 - val_loss: 0.6504 - val_accuracy: 0.6300 - 86s/epoch - 858ms/step\n",
            "Epoch 3/15\n",
            "100/100 - 88s - loss: 0.6523 - accuracy: 0.6185 - val_loss: 0.6629 - val_accuracy: 0.6150 - 88s/epoch - 880ms/step\n",
            "Epoch 4/15\n",
            "100/100 - 90s - loss: 0.6273 - accuracy: 0.6555 - val_loss: 0.5652 - val_accuracy: 0.7110 - 90s/epoch - 903ms/step\n",
            "Epoch 5/15\n",
            "100/100 - 90s - loss: 0.5984 - accuracy: 0.6775 - val_loss: 0.6033 - val_accuracy: 0.6700 - 90s/epoch - 900ms/step\n",
            "Epoch 6/15\n",
            "100/100 - 90s - loss: 0.5805 - accuracy: 0.6935 - val_loss: 0.6141 - val_accuracy: 0.6470 - 90s/epoch - 902ms/step\n",
            "Epoch 7/15\n",
            "100/100 - 81s - loss: 0.5758 - accuracy: 0.7075 - val_loss: 0.5757 - val_accuracy: 0.6950 - 81s/epoch - 812ms/step\n",
            "Epoch 8/15\n",
            "100/100 - 89s - loss: 0.5682 - accuracy: 0.7080 - val_loss: 0.5834 - val_accuracy: 0.7000 - 89s/epoch - 891ms/step\n",
            "Epoch 9/15\n",
            "100/100 - 80s - loss: 0.5724 - accuracy: 0.7030 - val_loss: 0.5640 - val_accuracy: 0.7080 - 80s/epoch - 797ms/step\n",
            "Epoch 10/15\n",
            "100/100 - 90s - loss: 0.5506 - accuracy: 0.7160 - val_loss: 0.5397 - val_accuracy: 0.7300 - 90s/epoch - 895ms/step\n",
            "Epoch 11/15\n",
            "100/100 - 90s - loss: 0.5466 - accuracy: 0.7185 - val_loss: 0.5271 - val_accuracy: 0.7370 - 90s/epoch - 899ms/step\n",
            "Epoch 12/15\n",
            "100/100 - 92s - loss: 0.5306 - accuracy: 0.7365 - val_loss: 0.5186 - val_accuracy: 0.7380 - 92s/epoch - 923ms/step\n",
            "Epoch 13/15\n",
            "100/100 - 89s - loss: 0.5017 - accuracy: 0.7530 - val_loss: 0.5961 - val_accuracy: 0.6740 - 89s/epoch - 889ms/step\n",
            "Epoch 14/15\n",
            "100/100 - 92s - loss: 0.5197 - accuracy: 0.7395 - val_loss: 0.5281 - val_accuracy: 0.7430 - 92s/epoch - 920ms/step\n",
            "Epoch 15/15\n",
            "100/100 - 89s - loss: 0.5072 - accuracy: 0.7490 - val_loss: 0.5450 - val_accuracy: 0.7210 - 89s/epoch - 890ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 6: Avaliar o modelo**"
      ],
      "metadata": {
        "id": "G5KTwooNZgU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o desempenho do modelo\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "print(f\"Loss: {loss}\")\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUElCvBIZjCx",
        "outputId": "44d074e1-02bf-4783-be63-a551b562870e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 67s 269ms/step - loss: 0.5375 - accuracy: 0.7279\n",
            "Loss: 0.5374932885169983\n",
            "Accuracy: 0.7278911471366882\n"
          ]
        }
      ]
    }
  ]
}